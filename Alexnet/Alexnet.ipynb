{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Alex:\n",
    "    def __init__(self, batch_size):\n",
    "        self.learning_rate = 0.0002\n",
    "        self.training_epoch = 100\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "    def conv2d(self, inputs,filters, kernel_size,strdies = (1,1),padding = \"SAME\"):\n",
    "        net = tf.layers.conv2d(inputs = inputs , filters= filters, kernel_size=kernel_size,strides = strides, padding=padding)\n",
    "        net = tf.nn.relu(net)\n",
    "        return net\n",
    "        \n",
    "    def max_pool(self, inputs):\n",
    "        return tf.layers.max_pooling2d(inputs, pool_size = (3,3), strides= (2,2))\n",
    "    \n",
    "    def Network(self, inputs):\n",
    "        with tf.variable_scope(\"Alexnet\"):\n",
    "            net = self.conv2d(inputs = inputs, filters = 96, kernel_size=[11,11], strides = (4,4), padding = \"VALID\")\n",
    "            net = self.conv2d(inputs = net , filters= 256, kernel_size=[5,5], strides = (4,4))\n",
    "            net = tf.nn.local_response_normalization(net) \n",
    "            \n",
    "            net = self.max_pool(net)\n",
    "            net = self.conv2d(inputs = net, filters =384, kernel_size=(3,3))\n",
    "            net = tf.nn.local_response_normalization(net)\n",
    "            \n",
    "            net = self.max_pool(net)\n",
    "            net = self.conv2d(inputs = net, filters = 384, kernel_size=(3,3))\n",
    "            net = self.conv2d(inputs = net, filters = 384, kernel_size=(3,3))\n",
    "            \n",
    "            net = self.conv2d(inputs = net, filters = 256, kernel_size=(3,3))\n",
    "            net = self.max_pool(net)\n",
    "            net = tf.layers.flatten(net)\n",
    "            \n",
    "            net = tf.layers.dense(inputs = net, units = 4096)\n",
    "            net = tf.nn.dropout(net, keep_prob=0.5)\n",
    "            net = tf.layers.dense(inputs = net, units = 4096)\n",
    "            net = tf.nn.dropout(net, keep_prob=0.5)\n",
    "            net = tf.layers.dense(inputs = net , units = 1000)\n",
    "            \n",
    "        return net\n",
    "    \n",
    "    def build_model(self):\n",
    "        x = tf.placeholder(tf.float32, shape = [None, 224,224,3])\n",
    "        y = tf.placeholder(tf.float32, shape = [None, 1000])\n",
    "        \n",
    "        self.logit = self.Network(x)\n",
    "        self.loss = tf.nn.sigmoid_cross_entropy_with_logits(logits = self.logit,labels= y)\n",
    "        self.trainer = tf.train.GradientDescentOptimizer(learning_rate = self.learning_rate).minimize(self.loss)\n",
    "        \n",
    "    def train(self):\n",
    "        \n",
    "        with tf.Session() as sess:\n",
    "            init = tf.global_variables_initializer()\n",
    "            sess.run(init)\n",
    "            \n",
    "            \n",
    "            for epoch in range(self.training_epoch):\n",
    "                total_batch = int(self.batch_size)\n",
    "                for iteration in range(total_batch):\n",
    "                    \n",
    "                    \n",
    "            \n",
    "            \n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
